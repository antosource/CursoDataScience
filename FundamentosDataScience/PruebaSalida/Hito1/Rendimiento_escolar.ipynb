{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hito1 para Rendimiento Escolar\n",
    "*\"Generar un modelo que identifique aquellos alumnos que presentan un bajo desempeño académico, medido en el promedio final del año escolar y perfilar los alumnos. Mediante un archivo con registros sociodemográficos y conductuales de los alumnos de dos escuelas portugesas\"*\n",
    "\n",
    "*\"Se sugiere explorar atributos ambientales del alumno para ver si pueden ser abstraídos en categorías latentes.\"*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminares\n",
    "\n",
    "#### Tipo de Problema a resolver: <code>**Regresión.**</code>\n",
    "- Es de regresión debido a que la variable objetivo tiene valores continuos, definida como el promedio de notas de los alumnos.\n",
    "\n",
    "Variable objetivo:\n",
    " \n",
    "- <code>G1: numérica</code>. Notas durante el primer semestre (VO 1 modelo descriptivo).\n",
    "- <code>G2: numérica</code>. Notas durante el segundo semestre (VO 2 modelo descriptivo).\n",
    "- <code>G3: numérica</code>. Promedio final (VO 3 modelo descriptivo, y VO modelo predictivo).\n",
    "\n",
    "\n",
    "#### Medicion de desempeño:\n",
    "\n",
    "- <code>MSE (Error cuadrático medio)</code>: Este se define a partir de las distancias entre el valor estimado y el valor real de la variable objetivo de nuestro modelo. (Nos permite medir la calidad de  nuestro ajuste, e idealmente queremos que sea pequeño.)\n",
    "\n",
    "- <code>r2_score</code>: representa la proporción porcentual de la varianza total de la variable objetivo que es explicada por los atributos agregados al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspectos computacionales\n",
    "\n",
    "- <code>Python v3.9.5</code>\n",
    "\n",
    "Las librerias utilizadas son:\n",
    "\n",
    "- <code>numpy </code>v1.22.3 : Proporciona una estructura de datos universal que posibilita el análisis de datos y el intercambio de datos entre distintos algoritmos. Las estructuras de datos que implementa son vectores multidimensionales y matrices con capacidad para gran cantidad de datos. Además, esta librería proporciona funciones matemáticas de alto nivel que operan en estas estructuras de datos.\n",
    "\n",
    "- <code>pandas</code> v1.4.2 : Una de las librerías de python más útiles para los científicos de datos. Las estructuras de datos principales en pandas son Series para datos en una dimensión y DataFrame para datos en dos dimensiones. Estas son las estructuras de datos más usadas en muchos campos tales como finanzas, estadística, ciencias sociales y muchas áreas de ingeniería. Pandas destaca por lo fácil y flexible que hace la manipulación de datos y el análisis de datos.\n",
    "\n",
    "- <code>matplotlib</code> v3.5.2 : librería gráfica de python estándar y la más conocida. Puedes usar matplotlib para generar gráficos de calidad necesaria para publicarlas tanto en papel como digitalmente. Con matplotlib puedes crear muchos tipos de gráficos: series temporales, histogramas, espectros de potencia, diagramas de barras, diagramas de errores, etc.\n",
    "\n",
    "- <code>seaborn</code> v0.11.2 : Librería gráfica basada en matplotlib, especializada en la visualización de datos estadísticos. Se caracteriza por ofrecer un interfaz de alto nivel para crear gráficos estadísticos visualmente atractivos e informativos. Seaborn considera la visualización como un aspecto fundamental a la hora de explorar y entender los datos. Se integra muy bien con la librería de manipulación de datos pandas.\n",
    "\n",
    "- <code>scipy</code> v1.8.0 Proporciona rutinas numéricas eficientes fáciles de usar y opera en las mismas estructuras de datos proporcionadas por NumPy. Por ejemplo, con SciPy puedes realizar: integración numérica, optimización, interpolación, transformadas de Fourier, álgebra lineal, estadística, etc.\n",
    " \n",
    "- <code>statsmodels</code> v0.13.2 :  Proporciona clases y funciones para la estimación de muchos modelos estadísticos diferentes, así como para realizar pruebas estadísticas y exploración de datos estadísticos. Hay disponible una lista extensa de estadísticas de resultados para cada estimador. Los resultados se comparan con paquetes estadísticos existentes para garantizar que sean correctos.\n",
    "\n",
    "- <code>sklearn</code> 1.1.1 : Es una librería de python para Machine Learning y Análisis de Datos. Está basada en NumPy, SciPy y Matplotlib. La ventajas principales de scikit-learn son su facilidad de uso y la gran cantidad de técnicas de aprendizaje automático que implementa. Con scikit-learn podemos realizar aprendizaje supervisado y no supervisado. Podemos usarlo para resolver problemas tanto de clasificación y como de regresión.\n",
    "- <code>warnings</code> El uso de esta libreria en nuestro codigo permite evitar los mensajes de advertencia mediante <code>filterwarnings()</code> *(warnings.filterwarnings('ignore'))*. \n",
    "\n",
    "Las librerias propias a utilizar son:\n",
    "\n",
    "- <code>calidad_datos2 </code>: Permite analizar los nulos y la calidad de los datos a analizar en general, tambien entrega medidas de interes como limite superior, inferior distancia IQR, media, desvición estandar, etc. \n",
    "\n",
    "- <code>gráficos</code> : Función con gráficos de interes para análisis de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de evaluación, preprocesamiento y recodificación de datos.\n",
    "\n",
    "Se hará un análisis exploratorio de las variables para realizar el preprocesamiento:\n",
    "\n",
    "- Se eliminaran del modelo los valores nulos, perdidos y caracteres incorrectos o anomalos, tambien se cambiaran los valores en texto a numeros. Tanto antes como despues de esta depuracion se utilizará <code>calidad_datos2 </code>que nos permite tener una perspectiva global.\n",
    "\n",
    "- Se realizara un <code>estudio de dimensionalidad</code> mediante el algoritmo de <code>Kmeans de la librería Sklearn </code>para estudiar la medida de similitud entre los atributos y considerar agrupar variables.\n",
    "\n",
    "- Se realizará una<code> exploración de correlaciones</code> entre atributos y variable objetivo. Para considerar la eventual exclusion del modelo dependendiendo si se correlacionan fuertemente\n",
    "\n",
    "- Transformación de variables categóricas aplicando dummies: <code>pd.get_dummies</code> (binary encoding)\n",
    "\n",
    "- Transformación de variables binarias a <code>0 y 1</code>. Se considerará como 1 la categoría minoritaria.\n",
    "\n",
    "- Tambien se explorarán las variables numéricas para evaluar su estandarización de escalas (usando <code>StandardScaler</code> de la librería <code>Sklearn</code> restando la media y dividiendo por la desviación estándar)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
